{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¹„ëª¨ìˆ˜ ë¶„ì„ ì¢…í•© í…œí”Œë¦¿ (All-in-One)",
    "",
    "ì´ ë…¸íŠ¸ë¶ì€ `nonparametric_analysis` íŒ¨í‚¤ì§€ê°€ ì œê³µí•˜ëŠ” **17ì¢…ì˜ ëª¨ë“  ë¶„ì„ ê¸°ëŠ¥**ì„ ì˜ˆì‹œì™€ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.",
    "ê° ê²°ê³¼ ì•„ë˜ì—ëŠ” **í†µê³„ ë¹„ì „ë¬¸ê°€ë¥¼ ìœ„í•œ 'ê²°ê³¼ í•´ì„ ê°€ì´ë“œ'**ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport warnings\n\n# Jupyterìš© matplotlib ì„¤ì •\n%matplotlib inline\n\n# ê²½ê³  ë¬´ì‹œ\nwarnings.filterwarnings('ignore')\n\n%load_ext autoreload\n%autoreload 2\n\n# Add src to path\nsys.path.append(str(Path('../03_Code/src').resolve()))\n\nimport matplotlib.pyplot as plt\nfrom nonparametric_analysis.analysis import nonparametric_methods as np_methods\nfrom nonparametric_analysis.analysis import utils\nfrom nonparametric_analysis.analysis.visualizations import setup_visualization\n\nsetup_visualization() # í•œê¸€ í°íŠ¸ ë° ìŠ¤íƒ€ì¼ ì„¤ì •\n\ndef show_result(res):\n    \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜\"\"\"\n    print(\"=\" * 55)\n    print(\"  ë¶„ì„ ê²°ê³¼ ìš”ì•½\")\n    print(\"=\" * 55)\n    for k, v in res.items():\n        if k == 'figure':\n            continue\n        if isinstance(v, pd.DataFrame):\n            print(f\"\\n  [{k}]\")\n            display(v)\n        elif isinstance(v, float):\n            print(f\"  {k:.<30s} {v:.4f}\")\n        else:\n            print(f\"  {k:.<30s} {v}\")\n    print(\"=\" * 55)\n    plt.show()"
  },
  {
   "cell_type": "code",
   "id": "ihmmwrdtb6j",
   "source": [
    "# ============================================================\n",
    "#   ğŸ”§ ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”! (ë¶„ì„ ì„¤ì •)\n",
    "# ============================================================\n",
    "\n",
    "# 0. ë°ì´í„° ì…ë ¥ ë°©ì‹ ì„ íƒ\n",
    "#    ë°©ë²• A: CSV íŒŒì¼ â†’ FILE_NAMEì— íŒŒì¼ëª… ì…ë ¥ (ê¸°ë³¸)\n",
    "#    ë°©ë²• B: ë³µì‚¬/ë¶™ì—¬ë„£ê¸° â†’ PASTE_DATAì— ë°ì´í„° ì§ì ‘ ë¶™ì—¬ë„£ê¸°\n",
    "#           (DRM ë¬¸ì„œ ë“± íŒŒì¼ ì €ì¥ì´ ì–´ë ¤ìš´ ê²½ìš° ì‚¬ìš©)\n",
    "PASTE_DATA = \"\"\"\n",
    "\"\"\"\n",
    "# â†‘ ë¶™ì—¬ë„£ê¸° ì‚¬ìš©ë²•:\n",
    "#   1. ìœ„ ìŒë”°ì˜´í‘œ ì‚¬ì´ì˜ ë¹ˆ ì¤„ì— ì»¤ì„œë¥¼ ë†“ìœ¼ì„¸ìš”\n",
    "#   2. ì›ë³¸ ë¬¸ì„œì—ì„œ ë°ì´í„°ë¥¼ ë³µì‚¬(Ctrl+C)í•˜ì„¸ìš”\n",
    "#   3. ì—¬ê¸°ì— ë¶™ì—¬ë„£ê¸°(Ctrl+V)í•˜ì„¸ìš”\n",
    "#   4. ì²« í–‰ì€ ë°˜ë“œì‹œ ì»¬ëŸ¼ëª…ì´ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "#\n",
    "# ì˜ˆì‹œ (ì‰¼í‘œ êµ¬ë¶„):\n",
    "# PASTE_DATA = \"\"\"\n",
    "# ì´ë¦„,ë§¤ì¶œì•¡,ì§€ì—­\n",
    "# ê¹€ì² ìˆ˜,1520,ì„œìš¸\n",
    "# ì´ì˜í¬,1680,ë¶€ì‚°\n",
    "# \"\"\"\n",
    "#\n",
    "# ì˜ˆì‹œ (íƒ­ êµ¬ë¶„ - Excelì—ì„œ ë³µì‚¬ ì‹œ):\n",
    "# PASTE_DATA = \"\"\"\n",
    "# ì´ë¦„\të§¤ì¶œì•¡\tì§€ì—­\n",
    "# ê¹€ì² ìˆ˜\t1520\tì„œìš¸\n",
    "# \"\"\"\n",
    "# â†’ ì‰¼í‘œ, íƒ­, ì„¸ë¯¸ì½œë¡  ëª¨ë‘ ìë™ ì¸ì‹ë©ë‹ˆë‹¤.\n",
    "\n",
    "# 1. CSV íŒŒì¼ ì´ë¦„ (PASTE_DATAê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ ì‚¬ìš©ë¨)\n",
    "#    02_Data/ í´ë”ì— CSV íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”\n",
    "FILE_NAME = \"sample_nonparametric.csv\"\n",
    "\n",
    "# 2. ë¶„ì„í•  ìˆ«ì ì»¬ëŸ¼ (ì‹œê³„ì—´/ë‹¨ì¼ë³€ìˆ˜ ë¶„ì„ ëŒ€ìƒ)\n",
    "TARGET_COLUMN = \"feature_1\"\n",
    "\n",
    "# 3. ë‘ ê·¸ë£¹ ë¹„êµ ì„¤ì • (Mann-Whitney, K-S ê²€ì •ìš©)\n",
    "#    ì‚¬ìš© ì•ˆ í•˜ë©´ ë¹ˆ ë¬¸ìì—´(\"\")ë¡œ ë‘ì„¸ìš”\n",
    "GROUP_COLUMN   = \"group\"        # ê·¸ë£¹ì„ êµ¬ë¶„í•˜ëŠ” ì»¬ëŸ¼\n",
    "GROUP_A_VALUE  = \"control\"      # Aê·¸ë£¹ ê°’\n",
    "GROUP_B_VALUE  = \"treatment\"    # Bê·¸ë£¹ ê°’\n",
    "\n",
    "# 4. ì „/í›„ ë¹„êµ ì„¤ì • (Wilcoxon, ë¶€í˜¸ ê²€ì •ìš©)\n",
    "#    ì‚¬ìš© ì•ˆ í•˜ë©´ ë¹ˆ ë¬¸ìì—´(\"\")ë¡œ ë‘ì„¸ìš”\n",
    "BEFORE_COLUMN  = \"\"             # ì²˜ë¦¬ ì „ ì¸¡ì •ê°’ ì»¬ëŸ¼ëª…\n",
    "AFTER_COLUMN   = \"\"             # ì²˜ë¦¬ í›„ ì¸¡ì •ê°’ ì»¬ëŸ¼ëª…\n",
    "\n",
    "# 5. ë‹¤ì¤‘ ë…ë¦½ ê·¸ë£¹ ë¹„êµ (Kruskal-Wallisìš©, 3ê°œ ì´ìƒ)\n",
    "#    GROUP_COLUMNì— ìˆëŠ” ê°’ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë„£ìœ¼ì„¸ìš”\n",
    "MULTI_GROUP_VALUES = []         # ì˜ˆ: [\"ì„œìš¸\", \"ë¶€ì‚°\", \"ëŒ€êµ¬\"]\n",
    "\n",
    "# 6. ë°˜ë³µ ì¸¡ì • ë¹„êµ (Friedmanìš©, ë™ì¼ ëŒ€ìƒì˜ ì—¬ëŸ¬ ì‹œì  ì¸¡ì •)\n",
    "#    ê° ì‹œì ì´ ë³„ë„ ì»¬ëŸ¼ì´ì–´ì•¼ í•©ë‹ˆë‹¤\n",
    "REPEATED_COLUMNS = []           # ì˜ˆ: [\"1ì›”_ì ìˆ˜\", \"3ì›”_ì ìˆ˜\", \"6ì›”_ì ìˆ˜\"]\n",
    "\n",
    "# 7. ìƒê´€ë¶„ì„ ì»¬ëŸ¼ (ë¹„ì›Œë‘ë©´ ëª¨ë“  ìˆ«ì ì»¬ëŸ¼ ìë™ ì‚¬ìš©)\n",
    "CORRELATION_COLUMNS = []        # ì˜ˆ: [\"ë§¤ì¶œì•¡\", \"ê´‘ê³ ë¹„\", \"ë°©ë¬¸ìˆ˜\"]\n",
    "\n",
    "# ============================================================\n",
    "#   â¬‡ï¸ ì•„ë˜ë¶€í„°ëŠ” ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”!\n",
    "# ============================================================"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "arugdzjy9mc",
   "source": [
    "# --- ë°ì´í„° ë¡œë“œ, ê²€ì¦, ì¤€ë¹„ (ìˆ˜ì • ë¶ˆí•„ìš”) ---\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "# 1) ë°ì´í„° ë¡œë“œ (ë¶™ì—¬ë„£ê¸° ë˜ëŠ” CSV íŒŒì¼)\n",
    "if PASTE_DATA.strip():\n",
    "    # ë¶™ì—¬ë„£ê¸° ë°ì´í„° ì‚¬ìš©\n",
    "    df = pd.read_csv(StringIO(PASTE_DATA.strip()), sep=None, engine=\"python\")\n",
    "    _data_source = \"ë¶™ì—¬ë„£ê¸°\"\n",
    "    print(\"=\" * 55)\n",
    "    print(\"  ğŸ“‹ ë¶™ì—¬ë„£ê¸° ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(\"=\" * 55)\n",
    "else:\n",
    "    # CSV íŒŒì¼ ì‚¬ìš©\n",
    "    data_path = Path(f\"../02_Data/{FILE_NAME}\")\n",
    "    if not data_path.exists():\n",
    "        data_dir = Path(\"../02_Data\")\n",
    "        existing = [f for f in os.listdir(data_dir) if f.endswith(\".csv\")] if data_dir.exists() else []\n",
    "        raise FileNotFoundError(\n",
    "            f\"\\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_NAME}\\n\"\n",
    "            f\"   02_Data/ í´ë”ì— CSV íŒŒì¼ì„ ë„£ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\\n\"\n",
    "            f\"   í˜„ì¬ CSV íŒŒì¼ ëª©ë¡: {existing}\"\n",
    "        )\n",
    "    df = pd.read_csv(data_path)\n",
    "    _data_source = f\"CSV íŒŒì¼ ({FILE_NAME})\"\n",
    "    print(\"=\" * 55)\n",
    "    print(\"  ğŸ“‚ CSV íŒŒì¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "print(f\"  ë°ì´í„° ì¶œì²˜........... {_data_source}\")\n",
    "print(f\"  í–‰ ìˆ˜................ {len(df):,}ê°œ\")\n",
    "print(f\"  ì—´ ìˆ˜................ {len(df.columns)}ê°œ\")\n",
    "print()\n",
    "print(\"  ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:\")\n",
    "for col in df.columns:\n",
    "    dtype = \"ìˆ«ì\" if df[col].dtype in ['int64', 'float64'] else \"ë¬¸ì\"\n",
    "    null_cnt = df[col].isna().sum()\n",
    "    null_str = f\", ê²°ì¸¡ {null_cnt}ê°œ\" if null_cnt > 0 else \"\"\n",
    "    print(f\"    - {col} ({dtype}{null_str})\")\n",
    "print()\n",
    "\n",
    "# 3) ì„¤ì •ê°’ ê²€ì¦\n",
    "errors = []\n",
    "if not TARGET_COLUMN:\n",
    "    errors.append(\"TARGET_COLUMNì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¶„ì„í•  ìˆ«ì ì»¬ëŸ¼ì„ ì§€ì •í•˜ì„¸ìš”.\")\n",
    "elif TARGET_COLUMN not in df.columns:\n",
    "    errors.append(f\"TARGET_COLUMN '{TARGET_COLUMN}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "elif not pd.api.types.is_numeric_dtype(df[TARGET_COLUMN]):\n",
    "    errors.append(f\"TARGET_COLUMN '{TARGET_COLUMN}'ì´(ê°€) ìˆ«ì ì»¬ëŸ¼ì´ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "\n",
    "if GROUP_COLUMN:\n",
    "    if GROUP_COLUMN not in df.columns:\n",
    "        errors.append(f\"GROUP_COLUMN '{GROUP_COLUMN}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "    else:\n",
    "        vals = df[GROUP_COLUMN].unique()\n",
    "        if GROUP_A_VALUE and GROUP_A_VALUE not in vals:\n",
    "            errors.append(f\"GROUP_A_VALUE '{GROUP_A_VALUE}'ì´(ê°€) '{GROUP_COLUMN}' ì»¬ëŸ¼ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {list(vals)}\")\n",
    "        if GROUP_B_VALUE and GROUP_B_VALUE not in vals:\n",
    "            errors.append(f\"GROUP_B_VALUE '{GROUP_B_VALUE}'ì´(ê°€) '{GROUP_COLUMN}' ì»¬ëŸ¼ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {list(vals)}\")\n",
    "        for mv in MULTI_GROUP_VALUES:\n",
    "            if mv not in vals:\n",
    "                errors.append(f\"MULTI_GROUP_VALUESì˜ '{mv}'ì´(ê°€) '{GROUP_COLUMN}' ì»¬ëŸ¼ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {list(vals)}\")\n",
    "\n",
    "if BEFORE_COLUMN and BEFORE_COLUMN not in df.columns:\n",
    "    errors.append(f\"BEFORE_COLUMN '{BEFORE_COLUMN}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "if AFTER_COLUMN and AFTER_COLUMN not in df.columns:\n",
    "    errors.append(f\"AFTER_COLUMN '{AFTER_COLUMN}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "\n",
    "for rc in REPEATED_COLUMNS:\n",
    "    if rc not in df.columns:\n",
    "        errors.append(f\"REPEATED_COLUMNSì˜ '{rc}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "\n",
    "for cc in CORRELATION_COLUMNS:\n",
    "    if cc not in df.columns:\n",
    "        errors.append(f\"CORRELATION_COLUMNSì˜ '{cc}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"âŒ ì„¤ì • ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤:\")\n",
    "    for e in errors:\n",
    "        print(f\"   - {e}\")\n",
    "    print(\"\\n  â¬†ï¸ ìœ„ì˜ 'ì„¤ì • ì…€'ì„ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    raise ValueError(\"ì„¤ì • ì˜¤ë¥˜ - ìœ„ì˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âœ… ì„¤ì • ê²€ì¦ ì™„ë£Œ!\")\n",
    "\n",
    "# 4) ë¶„ì„ ë°ì´í„° ì¤€ë¹„\n",
    "series = df[TARGET_COLUMN].dropna()\n",
    "\n",
    "# ë‘ ê·¸ë£¹ ë¹„êµ\n",
    "if GROUP_COLUMN and GROUP_A_VALUE and GROUP_B_VALUE:\n",
    "    group_a = df[df[GROUP_COLUMN] == GROUP_A_VALUE][TARGET_COLUMN].dropna()\n",
    "    group_b = df[df[GROUP_COLUMN] == GROUP_B_VALUE][TARGET_COLUMN].dropna()\n",
    "    HAS_TWO_GROUPS = len(group_a) > 0 and len(group_b) > 0\n",
    "else:\n",
    "    group_a, group_b = pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "    HAS_TWO_GROUPS = False\n",
    "\n",
    "# ì „/í›„ ë¹„êµ\n",
    "if BEFORE_COLUMN and AFTER_COLUMN:\n",
    "    before = df[BEFORE_COLUMN].dropna().values\n",
    "    after = df[AFTER_COLUMN].dropna().values\n",
    "    min_len = min(len(before), len(after))\n",
    "    before, after = before[:min_len], after[:min_len]\n",
    "    HAS_PAIRED = min_len > 0\n",
    "else:\n",
    "    before, after = None, None\n",
    "    HAS_PAIRED = False\n",
    "\n",
    "# ë‹¤ì¤‘ ë…ë¦½ ê·¸ë£¹\n",
    "if GROUP_COLUMN and len(MULTI_GROUP_VALUES) >= 3:\n",
    "    multi_groups = [\n",
    "        df[df[GROUP_COLUMN] == v][TARGET_COLUMN].dropna().values\n",
    "        for v in MULTI_GROUP_VALUES\n",
    "    ]\n",
    "    HAS_MULTI_GROUPS = all(len(g) > 0 for g in multi_groups)\n",
    "else:\n",
    "    multi_groups = []\n",
    "    HAS_MULTI_GROUPS = False\n",
    "\n",
    "# ë°˜ë³µ ì¸¡ì •\n",
    "if len(REPEATED_COLUMNS) >= 3:\n",
    "    repeated_data = [df[col].dropna().values for col in REPEATED_COLUMNS]\n",
    "    min_repeated = min(len(d) for d in repeated_data)\n",
    "    repeated_data = [d[:min_repeated] for d in repeated_data]\n",
    "    HAS_REPEATED = min_repeated > 0\n",
    "else:\n",
    "    repeated_data = []\n",
    "    HAS_REPEATED = False\n",
    "\n",
    "# ìƒê´€ë¶„ì„\n",
    "if CORRELATION_COLUMNS:\n",
    "    corr_df = df[CORRELATION_COLUMNS].dropna()\n",
    "else:\n",
    "    corr_df = df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "# 5) ì¤€ë¹„ ê²°ê³¼ ìš”ì•½\n",
    "print()\n",
    "print(\"=\" * 55)\n",
    "print(\"  ğŸ“Š ë¶„ì„ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"  ë‹¨ì¼ë³€ìˆ˜ (series)........ {len(series)}ê°œ\")\n",
    "if HAS_TWO_GROUPS:\n",
    "    print(f\"  ë‘ ê·¸ë£¹ ë¹„êµ............ âœ… {GROUP_A_VALUE}({len(group_a)}ê°œ) vs {GROUP_B_VALUE}({len(group_b)}ê°œ)\")\n",
    "else:\n",
    "    print(f\"  ë‘ ê·¸ë£¹ ë¹„êµ............ â­ï¸ ê±´ë„ˆëœ€ (ë¯¸ì„¤ì •)\")\n",
    "if HAS_PAIRED:\n",
    "    print(f\"  ì „/í›„ ë¹„êµ.............. âœ… {min_len}ìŒ\")\n",
    "else:\n",
    "    print(f\"  ì „/í›„ ë¹„êµ.............. â­ï¸ ê±´ë„ˆëœ€ (ë¯¸ì„¤ì •)\")\n",
    "if HAS_MULTI_GROUPS:\n",
    "    print(f\"  ë‹¤ì¤‘ ê·¸ë£¹ ë¹„êµ.......... âœ… {len(MULTI_GROUP_VALUES)}ê°œ ê·¸ë£¹\")\n",
    "else:\n",
    "    print(f\"  ë‹¤ì¤‘ ê·¸ë£¹ ë¹„êµ.......... â­ï¸ ê±´ë„ˆëœ€ (ë¯¸ì„¤ì •)\")\n",
    "if HAS_REPEATED:\n",
    "    print(f\"  ë°˜ë³µ ì¸¡ì • ë¹„êµ.......... âœ… {len(REPEATED_COLUMNS)}ì‹œì  x {min_repeated}ê°œ\")\n",
    "else:\n",
    "    print(f\"  ë°˜ë³µ ì¸¡ì • ë¹„êµ.......... â­ï¸ ê±´ë„ˆëœ€ (ë¯¸ì„¤ì •)\")\n",
    "print(f\"  ìƒê´€ë¶„ì„ ì»¬ëŸ¼........... {len(corr_df.columns)}ê°œ\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5í–‰):\")\n",
    "display(df.head())"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 ì •ê·œì„± ê²€ì • (Normality Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.test_normality(series, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 ëŸ° ê²€ì • (Runs Test - ë¬´ì‘ìœ„ì„±)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.runs_test_analysis(series, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 ì¶”ì„¸ ë¶„ì„ (Mann-Kendall Trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.mann_kendall_test(series, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 ë³€ê³¡ì  íƒì§€ (Pettitt Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.pettitt_test(series, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 ë‹¤ì¤‘ êµ¬ê°„ ë¶„í•  (PELT)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.detect_changepoints_pelt(series, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ’¡ ê²°ê³¼ í•´ì„\n",
    "\n",
    "**ğŸ¯ ì´ ë¶„ì„ì˜ ëª©ì **: ë°ì´í„°ì˜ íŒ¨í„´ì´ ë°”ë€ŒëŠ” **ì—¬ëŸ¬ ì§€ì ì„ ë™ì‹œì—** ëª¨ë‘ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ğŸ“Š ê²°ê³¼ ì½ëŠ” ë²•**:\n",
    "- **Change Points = [10, 35, 78]** â†’ 3ê°œì˜ ë³€í™” ì§€ì  ë°œê²¬\n",
    "  - â†’ ë°ì´í„°ê°€ 4ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ë‰¨ (1~10, 11~35, 36~78, 79~ë)\n",
    "  - â†’ ê° êµ¬ê°„ë§ˆë‹¤ ë‹¤ë¥¸ íŠ¹ì„±(í‰ê· , ë¶„ì‚° ë“±)ì„ ê°€ì§\n",
    "- **Change Points = []** â†’ ë³€í™” ì§€ì  ì—†ìŒ\n",
    "  - â†’ ë°ì´í„°ê°€ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì¼ê´€ëœ íŒ¨í„´ ìœ ì§€\n",
    "\n",
    "**ğŸ’¼ ì‹¤ë¬´ í™œìš©**:\n",
    "- ì˜ˆ: ì‹œê°„ëŒ€ë³„ ì„œë²„ ë¶€í•˜ â†’ Change Points = [8, 12, 18, 22]\n",
    "  - íŒë‹¨: \"ì¶œê·¼(8ì‹œ), ì ì‹¬(12ì‹œ), í‡´ê·¼(18ì‹œ), ì‹¬ì•¼(22ì‹œ)ì— íŒ¨í„´ ë³€í™”. ê° ì‹œê°„ëŒ€ë³„ ë¦¬ì†ŒìŠ¤ í• ë‹¹ í•„ìš”\"\n",
    "- ì˜ˆ: ë¶„ê¸°ë³„ ë§¤ì¶œ â†’ Change Points = [90, 180]\n",
    "  - íŒë‹¨: \"90ì¼, 180ì¼ì°¨ì— ë§¤ì¶œ íŒ¨í„´ ë³€í™”. í•´ë‹¹ ì‹œì  í”„ë¡œëª¨ì…˜/ê³„ì ˆì„± ë¶„ì„\"\n",
    "- ì˜ˆ: ì œí’ˆ í’ˆì§ˆ â†’ Change Points = [150]\n",
    "  - íŒë‹¨: \"150ë²ˆì§¸ ì œí’ˆë¶€í„° í’ˆì§ˆ ë³€í™”. ê³µì • ë³€ê²½ ë˜ëŠ” ì›ìì¬ ë³€ê²½ ì‹œì  í™•ì¸\"\n",
    "\n",
    "**ğŸ“ˆ ì°¨íŠ¸ í™•ì¸**:\n",
    "- **ë¹¨ê°„ ìˆ˜ì§ì„ ë“¤**: ê° ë³€í™” ì§€ì  í‘œì‹œ\n",
    "- **êµ¬ê°„ë³„ ìƒ‰ìƒ**: ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„ëœ êµ¬ê°„ë“¤\n",
    "- **ê° êµ¬ê°„ì˜ í‰ê· ì„ **: êµ¬ê°„ë§ˆë‹¤ ë‹¤ë¥¸ ìˆ˜ì¤€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 ë‘ ë…ë¦½ ê·¸ë£¹ ë¹„êµ (Mann-Whitney U)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_TWO_GROUPS:\n    res = np_methods.mann_whitney_test(group_a, group_b, name1=GROUP_A_VALUE, name2=GROUP_B_VALUE)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ë‘ ê·¸ë£¹ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ GROUP_COLUMN, GROUP_A_VALUE, GROUP_B_VALUEë¥¼ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ë‘ ë¶„í¬ ë¹„êµ (K-S Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_TWO_GROUPS:\n    res = np_methods.ks_test(group_a, group_b, name1=GROUP_A_VALUE, name2=GROUP_B_VALUE)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ë‘ ë¶„í¬ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ GROUP_COLUMN, GROUP_A_VALUE, GROUP_B_VALUEë¥¼ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 ì§ì§€ì–´ì§„ ê·¸ë£¹ ë¹„êµ (Wilcoxon Signed Rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_PAIRED:\n    res = np_methods.wilcoxon_paired_test(before, after, name=f\"{BEFORE_COLUMN} vs {AFTER_COLUMN}\")\n    show_result(res)\nelse:\n    print(\"â­ï¸ ì „/í›„ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ BEFORE_COLUMN, AFTER_COLUMNì„ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n    print(\"   (ì˜ˆ: ë™ì¼ ëŒ€ìƒì˜ ì¹˜ë£Œ ì „/í›„, êµìœ¡ ì „/í›„ ì¸¡ì •ê°’)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 ë¶€í˜¸ ê²€ì • (Sign Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_PAIRED:\n    res = np_methods.sign_test(before, after)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ë¶€í˜¸ ê²€ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ BEFORE_COLUMN, AFTER_COLUMNì„ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 ì„¸ ë…ë¦½ ê·¸ë£¹ ë¹„êµ (Kruskal-Wallis)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_MULTI_GROUPS:\n    res = np_methods.kruskal_wallis_test(multi_groups, group_names=MULTI_GROUP_VALUES)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ë‹¤ì¤‘ ê·¸ë£¹ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ MULTI_GROUP_VALUESì— 3ê°œ ì´ìƒì˜ ê·¸ë£¹ê°’ì„ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n    print(\"   (ì˜ˆ: MULTI_GROUP_VALUES = [\\\"ì„œìš¸\\\", \\\"ë¶€ì‚°\\\", \\\"ëŒ€êµ¬\\\"])\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 ë°˜ë³µ ì¸¡ì • ë¹„êµ (Friedman Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_REPEATED:\n    res = np_methods.friedman_test(repeated_data, condition_names=REPEATED_COLUMNS)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ë°˜ë³µ ì¸¡ì • ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ REPEATED_COLUMNSì— 3ê°œ ì´ìƒì˜ ì‹œì  ì»¬ëŸ¼ì„ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n    print(\"   (ì˜ˆ: REPEATED_COLUMNS = [\\\"1ì›”_ì ìˆ˜\\\", \\\"3ì›”_ì ìˆ˜\\\", \\\"6ì›”_ì ìˆ˜\\\"])\")\n    print(\"   â€» ë™ì¼ ëŒ€ìƒì„ ì—¬ëŸ¬ ì‹œì ì— ì¸¡ì •í•œ ë°ì´í„°ì—¬ì•¼ í•©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ’¡ ê²°ê³¼ í•´ì„\n",
    "\n",
    "**ğŸ¯ ì´ ë¶„ì„ì˜ ëª©ì **: 3ê°œ ì´ìƒì˜ ì‹œì /ì¡°ê±´ì—ì„œ **ë™ì¼í•œ ëŒ€ìƒ**ì„ ë°˜ë³µ ì¸¡ì •í–ˆì„ ë•Œ ì°¨ì´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ğŸ“Š ê²°ê³¼ ì½ëŠ” ë²•**:\n",
    "- **p < 0.05** â†’ ì‹œì /ì¡°ê±´ ê°„ì— **ì°¨ì´ê°€ ì¡´ì¬**í•©ë‹ˆë‹¤\n",
    "  - â†’ ì ì–´ë„ í•œ ì‹œì ì´ ë‹¤ë¥¸ ì‹œì ë“¤ê³¼ ë‹¤ë¦„\n",
    "  - â†’ ì‹œê°„ì— ë”°ë¥¸ ë³€í™” ë˜ëŠ” ì¡°ê±´ íš¨ê³¼ê°€ ìˆìŒ\n",
    "- **p â‰¥ 0.05** â†’ ì‹œì /ì¡°ê±´ ê°„ì— **ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤**\n",
    "  - â†’ ì‹œê°„ì´ ì§€ë‚˜ë„ ë³€í™” ì—†ìŒ\n",
    "  - â†’ ì¡°ê±´ì„ ë°”ê¿”ë„ íš¨ê³¼ ì—†ìŒ\n",
    "\n",
    "**ğŸ’¬ ì‚¬ìš© ì¡°ê±´**:\n",
    "- **ë°˜ë“œì‹œ ë™ì¼ ëŒ€ìƒ**ì˜ ë°˜ë³µ ì¸¡ì •ì´ì–´ì•¼ í•¨\n",
    "- ì˜ˆ: ê°™ì€ í™˜ìë¥¼ 1ê°œì›”, 3ê°œì›”, 6ê°œì›” í›„ ì¸¡ì •\n",
    "\n",
    "**ğŸ’¼ ì‹¤ë¬´ í™œìš©**:\n",
    "- ì˜ˆ: ë‹¤ì´ì–´íŠ¸ í”„ë¡œê·¸ë¨ (ì‹œì‘/1ê°œì›”/3ê°œì›”/6ê°œì›”) â†’ p = 0.001\n",
    "  - íŒë‹¨: \"ì‹œê°„ì— ë”°ë¼ ì²´ì¤‘ ë³€í™” ìˆìŒ. ì‚¬í›„ê²€ì •ìœ¼ë¡œ ì–´ëŠ ì‹œì ì— ê°€ì¥ íš¨ê³¼ì ì¸ì§€ íŒŒì•…\"\n",
    "- ì˜ˆ: ì•½ë¬¼ ìš©ëŸ‰ (ì €ìš©ëŸ‰/ì¤‘ìš©ëŸ‰/ê³ ìš©ëŸ‰) ë™ì¼ í™˜ì â†’ p = 0.03\n",
    "  - íŒë‹¨: \"ìš©ëŸ‰ì— ë”°ë¼ íš¨ê³¼ ì°¨ì´ ìˆìŒ. ìµœì  ìš©ëŸ‰ ì°¾ê¸° ìœ„í•œ ì¶”ê°€ ë¶„ì„ í•„ìš”\"\n",
    "- ì˜ˆ: ê³„ì ˆë³„(ë´„/ì—¬ë¦„/ê°€ì„/ê²¨ìš¸) ë™ì¼ ë§¤ì¥ ë§¤ì¶œ â†’ p = 0.67\n",
    "  - íŒë‹¨: \"ê³„ì ˆ ì˜í–¥ ì—†ìŒ. ì—°ì¤‘ ì¼ê´€ëœ ë§ˆì¼€íŒ… ì „ëµ ìœ ì§€\"\n",
    "\n",
    "**ğŸ“ˆ ì°¨íŠ¸ í™•ì¸**:\n",
    "- **ì‹œì ë³„ Box Plot**: ì‹œì ì— ë”°ë¼ ìƒì ìœ„ì¹˜ê°€ ë°”ë€ŒëŠ”ì§€ í™•ì¸\n",
    "- **í‰ê·  ìˆœìœ„**: ì–´ëŠ ì‹œì ì˜ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ì§€/ë‚®ì€ì§€\n",
    "- **ë³€í™” ì¶”ì„¸ì„ **: ì‹œê°„ íë¦„ì— ë”°ë¥¸ íŒ¨í„´ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 ìƒê´€ í–‰ë ¬ (Heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if len(corr_df.columns) >= 2:\n    res = np_methods.correlation_matrix_nonparametric(corr_df)\n    show_result(res)\nelse:\n    print(\"â­ï¸ ìƒê´€ í–‰ë ¬ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ìˆ«ì ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 ë‹¤ì–‘í•œ ìƒê´€ ë¶„ì„ (Kendall, Distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "num_cols = corr_df.columns.tolist()\nif len(num_cols) >= 2:\n    x = corr_df[num_cols[0]]\n    y = corr_df[num_cols[1]]\n    print(f\"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {num_cols[0]} vs {num_cols[1]}\")\n    print()\n\n    res_k = np_methods.kendall_corr(x, y)\n    print(f\"Kendall Tau: {res_k['correlation']:.4f}, p-value: {res_k['p_value']:.4f}\")\n    plt.show()\n\n    res_d = np_methods.distance_correlation(x, y)\n    print(f\"Distance Corr: {res_d['dcor']:.4f}, p-value: {res_d['p_value']:.4f}\")\n    plt.show()\nelse:\n    print(\"â­ï¸ ê°œë³„ ìƒê´€ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ìˆ«ì ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ’¡ ê²°ê³¼ í•´ì„\n",
    "\n",
    "**ğŸ“Š Kendall Tau (ì¼„ë‹¬ íƒ€ìš°)**:\n",
    "- **ëª©ì **: ìˆœìœ„ ë™ì ì´ ë§ì„ ë•Œ ë” ì •í™•í•œ ìƒê´€ ë¶„ì„\n",
    "- **ê°’ í•´ì„**:\n",
    "  - **+1ì— ê°€ê¹Œì›€**: ê°•í•œ ì–‘ì˜ ê´€ê³„\n",
    "  - **0ì— ê°€ê¹Œì›€**: ê´€ê³„ ì—†ìŒ\n",
    "  - **-1ì— ê°€ê¹Œì›€**: ê°•í•œ ìŒì˜ ê´€ê³„\n",
    "- **Spearmanê³¼ì˜ ì°¨ì´**: ë™ì¼ ê°’(ë™ì )ì´ ë§ì„ ë•Œ ë” ì•ˆì •ì \n",
    "\n",
    "**ğŸ“Š Distance Correlation (ê±°ë¦¬ ìƒê´€)**:\n",
    "- **ëª©ì **: **ê³¡ì„  ê´€ê³„(ë¹„ì„ í˜•)**ë„ ì°¾ì•„ëƒ…ë‹ˆë‹¤\n",
    "- **ê°’ í•´ì„**:\n",
    "  - **0**: ì™„ì „íˆ ë…ë¦½ì  (ê´€ê³„ ì—†ìŒ)\n",
    "  - **1**: ì™„ì „íˆ ì¢…ì†ì  (ê°•í•œ ê´€ê³„)\n",
    "  - ì¤‘ìš”: í•­ìƒ 0~1 ì‚¬ì´ ê°’ (ìŒìˆ˜ ì—†ìŒ)\n",
    "- **ì¼ë°˜ ìƒê´€ê³¼ì˜ ì°¨ì´**: \n",
    "  - ì¼ë°˜ ìƒê´€: ì§ì„  ê´€ê³„ë§Œ ì°¾ìŒ (y = ax + b)\n",
    "  - Distance: ê³¡ì„  ê´€ê³„ë„ ì°¾ìŒ (y = xÂ², y = sin(x) ë“±)\n",
    "\n",
    "**ğŸ’¼ ì‹¤ë¬´ í™œìš©**:\n",
    "- ì˜ˆ: Kendall Tau = 0.75 vs Spearman = 0.68 (ë™ì  ë§ì€ ë°ì´í„°)\n",
    "  - íŒë‹¨: \"Kendallì´ ë” ì‹ ë¢°í•  ë§Œí•¨. Spearmanì€ ë™ì ì— ì·¨ì•½\"\n",
    "- ì˜ˆ: ì¼ë°˜ ìƒê´€ = 0.1, Distance ìƒê´€ = 0.8\n",
    "  - íŒë‹¨: \"ì§ì„  ê´€ê³„ëŠ” ì•½í•˜ì§€ë§Œ ê³¡ì„  ê´€ê³„ëŠ” ê°•í•¨. ë¹„ì„ í˜• ëª¨ë¸ ê³ ë ¤ í•„ìš”\"\n",
    "- ì˜ˆ: Distance ìƒê´€ = 0.05\n",
    "  - íŒë‹¨: \"ì§ì„ ì´ë“  ê³¡ì„ ì´ë“  ê´€ê³„ ì—†ìŒ. ë‘ ë³€ìˆ˜ ë…ë¦½ì \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‹ ë¢°êµ¬ê°„ (Bootstrap CI)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "res = np_methods.bootstrap_ci(series, stat_func=np.mean, n_boot=1000, name=TARGET_COLUMN)\nshow_result(res)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 ìˆœì—´ ê²€ì • (Permutation Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "if HAS_TWO_GROUPS:\n    res = np_methods.permutation_test(\n        group_a, group_b,\n        stat_func=np.mean, n_perm=1000,\n        name1=GROUP_A_VALUE, name2=GROUP_B_VALUE,\n    )\n    show_result(res)\nelse:\n    print(\"â­ï¸ ìˆœì—´ ê²€ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n    print(\"   â†’ ì„¤ì • ì…€ì—ì„œ GROUP_COLUMN, GROUP_A_VALUE, GROUP_B_VALUEë¥¼ ì§€ì •í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ğŸ’¡ ê²°ê³¼ í•´ì„\n",
    "\n",
    "**ğŸ¯ ì´ ë¶„ì„ì˜ ëª©ì **: ì •ê·œë¶„í¬ ê°€ì •ì´ ë¶ˆê°€ëŠ¥í•  ë•Œ, **ë‘ ê·¸ë£¹ì˜ ì°¨ì´ê°€ ìš°ì—°ì¸ì§€** ê²€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ğŸ“Š ê²°ê³¼ ì½ëŠ” ë²•**:\n",
    "- **p < 0.05** â†’ ë‘ ê·¸ë£¹ ì°¨ì´ê°€ **ì§„ì§œ**ì…ë‹ˆë‹¤\n",
    "  - â†’ ìš°ì—°ìœ¼ë¡œ ì´ëŸ° ì°¨ì´ê°€ ë‚˜ì˜¬ í™•ë¥  5% ë¯¸ë§Œ\n",
    "  - â†’ ê·¸ë£¹ Aì™€ BëŠ” ì‹¤ì œë¡œ ë‹¤ë¥¸ ëª¨ì§‘ë‹¨\n",
    "- **p â‰¥ 0.05** â†’ ë‘ ê·¸ë£¹ ì°¨ì´ê°€ **ìš°ì—°**ì…ë‹ˆë‹¤\n",
    "  - â†’ ìš´ì´ ë‚˜ë¹ ì„œ ì°¨ì´ê°€ ë‚œ ê²ƒì¼ ìˆ˜ ìˆìŒ\n",
    "  - â†’ ë‘ ê·¸ë£¹ì„ ë‹¤ë¥´ë‹¤ê³  ê²°ë¡  ë‚´ë¦´ ìˆ˜ ì—†ìŒ\n",
    "\n",
    "**ğŸ’¬ ìˆœì—´ê²€ì •ì´ë€?**:\n",
    "- ë°ì´í„°ë¥¼ **ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ** ê´€ì°°ëœ ì°¨ì´ê°€ ìš°ì—°ì¸ì§€ í™•ì¸\n",
    "- ì˜ˆ: ê·¸ë£¹ ë¼ë²¨ì„ 1000ë²ˆ ì„ì–´ë³´ê³ , ì›ë˜ ì°¨ì´ë³´ë‹¤ í° ì°¨ì´ê°€ ëª‡ ë²ˆ ë‚˜ì˜¤ëŠ”ì§€ ê³„ì‚°\n",
    "- ì •ê·œë¶„í¬, ë™ë¶„ì‚° ë“± **ì–´ë–¤ ê°€ì •ë„ í•„ìš” ì—†ìŒ**\n",
    "\n",
    "**ğŸ’¼ ì‹¤ë¬´ í™œìš©**:\n",
    "- ì˜ˆ: ì‹ ì•½ vs ìœ„ì•½ í‰ê·  ì°¨ì´ = 5, p = 0.002\n",
    "  - íŒë‹¨: \"ì°¨ì´ê°€ ìš°ì—°ì´ ì•„ë‹˜. ì‹ ì•½ì´ ì§„ì§œ íš¨ê³¼ ìˆìŒ. ì„ìƒ ì‹œí—˜ ì„±ê³µ\"\n",
    "- ì˜ˆ: A/B í…ŒìŠ¤íŠ¸ ì „í™˜ìœ¨ ì°¨ì´ = 2%, p = 0.35\n",
    "  - íŒë‹¨: \"2% ì°¨ì´ëŠ” ìš°ì—°ì¼ ìˆ˜ ìˆìŒ. Aì™€ B ì¤‘ ì–´ëŠ ê²ƒì´ ì¢‹ë‹¤ê³  ê²°ë¡  ëª» ë‚´ë¦¼. ìƒ˜í”Œ ë” ëª¨ìœ¼ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²• ì‹œë„\"\n",
    "- ì˜ˆ: ì‹œê°„ëŒ€ë³„ ë§¤ì¶œ ì°¨ì´ = 100ë§Œì›, p = 0.01\n",
    "  - íŒë‹¨: \"ì‹œê°„ëŒ€ë³„ ì°¨ì´ê°€ ì§„ì§œì„. í”¼í¬ ì‹œê°„ëŒ€ ì¸ë ¥ ë°°ì¹˜ ê°•í™” í•„ìš”\"\n",
    "\n",
    "**ğŸ“ˆ ì°¨íŠ¸ í™•ì¸**:\n",
    "- **ìˆœì—´ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨**: ìš°ì—°íˆ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ì°¨ì´ë“¤ì˜ ë¶„í¬\n",
    "- **ê´€ì°°ëœ ì°¨ì´ (ë¹¨ê°„ ì„ )**: ì‹¤ì œë¡œ ê´€ì°°ëœ ì°¨ì´\n",
    "- **ë¹¨ê°„ ì„ ì´ íˆìŠ¤í† ê·¸ë¨ ëì— ìœ„ì¹˜**: ë§¤ìš° ë“œë¬¸ ê²½ìš° â†’ ìš°ì—° ì•„ë‹˜ â†’ p ê°’ ì‘ìŒ"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}